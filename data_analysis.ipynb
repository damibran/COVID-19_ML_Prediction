{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df = pd.read_csv('abs_data.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FrEM_1.5_0_0</th>\n",
       "      <th>FrEM_1.5_0_1</th>\n",
       "      <th>FrEM_1.5_0_2</th>\n",
       "      <th>FrEM_1.5_0_3</th>\n",
       "      <th>FrEM_1.5_0_4</th>\n",
       "      <th>FrEM_1.5_0_5</th>\n",
       "      <th>FrEM_1.5_0_6</th>\n",
       "      <th>FrEM_1.5_0_7</th>\n",
       "      <th>FrEM_1.5_0_8</th>\n",
       "      <th>FrEM_1.5_1_0</th>\n",
       "      <th>...</th>\n",
       "      <th>FrEM_1.5_8_0</th>\n",
       "      <th>FrEM_1.5_8_1</th>\n",
       "      <th>FrEM_1.5_8_2</th>\n",
       "      <th>FrEM_1.5_8_3</th>\n",
       "      <th>FrEM_1.5_8_4</th>\n",
       "      <th>FrEM_1.5_8_5</th>\n",
       "      <th>FrEM_1.5_8_6</th>\n",
       "      <th>FrEM_1.5_8_7</th>\n",
       "      <th>FrEM_1.5_8_8</th>\n",
       "      <th>COVID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.994183</td>\n",
       "      <td>63.500354</td>\n",
       "      <td>23.764615</td>\n",
       "      <td>14.809006</td>\n",
       "      <td>10.132739</td>\n",
       "      <td>6.458623</td>\n",
       "      <td>6.079418</td>\n",
       "      <td>8.116356</td>\n",
       "      <td>6.566475</td>\n",
       "      <td>24.248562</td>\n",
       "      <td>...</td>\n",
       "      <td>2.626713</td>\n",
       "      <td>0.579372</td>\n",
       "      <td>0.493647</td>\n",
       "      <td>0.304215</td>\n",
       "      <td>0.524688</td>\n",
       "      <td>0.741711</td>\n",
       "      <td>0.647763</td>\n",
       "      <td>0.501151</td>\n",
       "      <td>0.800689</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>155.623148</td>\n",
       "      <td>56.797151</td>\n",
       "      <td>13.028535</td>\n",
       "      <td>6.626909</td>\n",
       "      <td>18.327383</td>\n",
       "      <td>21.185920</td>\n",
       "      <td>12.829356</td>\n",
       "      <td>8.488317</td>\n",
       "      <td>2.170785</td>\n",
       "      <td>28.747849</td>\n",
       "      <td>...</td>\n",
       "      <td>2.719659</td>\n",
       "      <td>0.752805</td>\n",
       "      <td>1.146061</td>\n",
       "      <td>0.545097</td>\n",
       "      <td>0.778240</td>\n",
       "      <td>0.335614</td>\n",
       "      <td>0.345323</td>\n",
       "      <td>0.875008</td>\n",
       "      <td>1.023703</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129.221184</td>\n",
       "      <td>78.454162</td>\n",
       "      <td>35.385913</td>\n",
       "      <td>14.856545</td>\n",
       "      <td>22.996153</td>\n",
       "      <td>26.209789</td>\n",
       "      <td>3.273651</td>\n",
       "      <td>8.038485</td>\n",
       "      <td>13.874770</td>\n",
       "      <td>33.070410</td>\n",
       "      <td>...</td>\n",
       "      <td>2.618402</td>\n",
       "      <td>1.192939</td>\n",
       "      <td>1.087911</td>\n",
       "      <td>0.424599</td>\n",
       "      <td>0.430478</td>\n",
       "      <td>0.243887</td>\n",
       "      <td>1.101742</td>\n",
       "      <td>0.878708</td>\n",
       "      <td>0.708836</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.390971</td>\n",
       "      <td>52.613964</td>\n",
       "      <td>27.395924</td>\n",
       "      <td>19.762264</td>\n",
       "      <td>25.765934</td>\n",
       "      <td>19.968011</td>\n",
       "      <td>7.511855</td>\n",
       "      <td>17.745597</td>\n",
       "      <td>2.505243</td>\n",
       "      <td>34.382638</td>\n",
       "      <td>...</td>\n",
       "      <td>2.952575</td>\n",
       "      <td>1.119850</td>\n",
       "      <td>1.417656</td>\n",
       "      <td>1.717594</td>\n",
       "      <td>0.808168</td>\n",
       "      <td>0.905884</td>\n",
       "      <td>1.340841</td>\n",
       "      <td>0.749654</td>\n",
       "      <td>1.203081</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.972250</td>\n",
       "      <td>64.084754</td>\n",
       "      <td>9.752420</td>\n",
       "      <td>19.138170</td>\n",
       "      <td>7.501705</td>\n",
       "      <td>13.622549</td>\n",
       "      <td>5.201777</td>\n",
       "      <td>2.111775</td>\n",
       "      <td>3.481266</td>\n",
       "      <td>30.666826</td>\n",
       "      <td>...</td>\n",
       "      <td>2.827844</td>\n",
       "      <td>0.086999</td>\n",
       "      <td>0.472183</td>\n",
       "      <td>0.830620</td>\n",
       "      <td>0.773404</td>\n",
       "      <td>0.326004</td>\n",
       "      <td>0.659731</td>\n",
       "      <td>0.117143</td>\n",
       "      <td>0.404780</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>49.290555</td>\n",
       "      <td>52.447780</td>\n",
       "      <td>30.949830</td>\n",
       "      <td>22.272996</td>\n",
       "      <td>28.822254</td>\n",
       "      <td>36.855464</td>\n",
       "      <td>10.118797</td>\n",
       "      <td>16.890644</td>\n",
       "      <td>1.069317</td>\n",
       "      <td>26.021889</td>\n",
       "      <td>...</td>\n",
       "      <td>1.213497</td>\n",
       "      <td>1.520239</td>\n",
       "      <td>1.408453</td>\n",
       "      <td>2.653076</td>\n",
       "      <td>0.821519</td>\n",
       "      <td>0.340801</td>\n",
       "      <td>1.145084</td>\n",
       "      <td>0.962714</td>\n",
       "      <td>1.747128</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>7.895864</td>\n",
       "      <td>40.140272</td>\n",
       "      <td>41.581360</td>\n",
       "      <td>31.097774</td>\n",
       "      <td>35.716285</td>\n",
       "      <td>58.725989</td>\n",
       "      <td>4.130060</td>\n",
       "      <td>13.639239</td>\n",
       "      <td>7.002448</td>\n",
       "      <td>41.124935</td>\n",
       "      <td>...</td>\n",
       "      <td>4.125636</td>\n",
       "      <td>0.354485</td>\n",
       "      <td>0.130846</td>\n",
       "      <td>1.322603</td>\n",
       "      <td>1.304823</td>\n",
       "      <td>1.435656</td>\n",
       "      <td>0.698340</td>\n",
       "      <td>1.433633</td>\n",
       "      <td>1.348833</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>141.097152</td>\n",
       "      <td>67.394794</td>\n",
       "      <td>40.584523</td>\n",
       "      <td>13.660300</td>\n",
       "      <td>18.929907</td>\n",
       "      <td>24.108398</td>\n",
       "      <td>9.341448</td>\n",
       "      <td>2.551847</td>\n",
       "      <td>7.145349</td>\n",
       "      <td>45.700588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866579</td>\n",
       "      <td>0.580831</td>\n",
       "      <td>0.847183</td>\n",
       "      <td>0.559834</td>\n",
       "      <td>0.398378</td>\n",
       "      <td>0.199093</td>\n",
       "      <td>0.910787</td>\n",
       "      <td>0.342122</td>\n",
       "      <td>0.443316</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>75.061793</td>\n",
       "      <td>47.387411</td>\n",
       "      <td>7.835419</td>\n",
       "      <td>22.178775</td>\n",
       "      <td>10.514467</td>\n",
       "      <td>27.084513</td>\n",
       "      <td>15.362545</td>\n",
       "      <td>1.225671</td>\n",
       "      <td>4.086449</td>\n",
       "      <td>13.058083</td>\n",
       "      <td>...</td>\n",
       "      <td>3.137124</td>\n",
       "      <td>0.416624</td>\n",
       "      <td>0.804608</td>\n",
       "      <td>0.550893</td>\n",
       "      <td>0.825911</td>\n",
       "      <td>0.417157</td>\n",
       "      <td>0.861060</td>\n",
       "      <td>0.533441</td>\n",
       "      <td>0.400909</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>89.132755</td>\n",
       "      <td>59.500009</td>\n",
       "      <td>39.355297</td>\n",
       "      <td>12.941851</td>\n",
       "      <td>24.474486</td>\n",
       "      <td>28.874037</td>\n",
       "      <td>24.960603</td>\n",
       "      <td>18.450276</td>\n",
       "      <td>9.148809</td>\n",
       "      <td>59.825875</td>\n",
       "      <td>...</td>\n",
       "      <td>2.537178</td>\n",
       "      <td>0.937049</td>\n",
       "      <td>0.918608</td>\n",
       "      <td>1.147427</td>\n",
       "      <td>2.367507</td>\n",
       "      <td>0.956245</td>\n",
       "      <td>1.162169</td>\n",
       "      <td>1.020073</td>\n",
       "      <td>2.780852</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FrEM_1.5_0_0  FrEM_1.5_0_1  FrEM_1.5_0_2  FrEM_1.5_0_3  FrEM_1.5_0_4  \\\n",
       "0      100.994183     63.500354     23.764615     14.809006     10.132739   \n",
       "1      155.623148     56.797151     13.028535      6.626909     18.327383   \n",
       "2      129.221184     78.454162     35.385913     14.856545     22.996153   \n",
       "3       90.390971     52.613964     27.395924     19.762264     25.765934   \n",
       "4       20.972250     64.084754      9.752420     19.138170      7.501705   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "372     49.290555     52.447780     30.949830     22.272996     28.822254   \n",
       "371      7.895864     40.140272     41.581360     31.097774     35.716285   \n",
       "296    141.097152     67.394794     40.584523     13.660300     18.929907   \n",
       "338     75.061793     47.387411      7.835419     22.178775     10.514467   \n",
       "237     89.132755     59.500009     39.355297     12.941851     24.474486   \n",
       "\n",
       "     FrEM_1.5_0_5  FrEM_1.5_0_6  FrEM_1.5_0_7  FrEM_1.5_0_8  FrEM_1.5_1_0  \\\n",
       "0        6.458623      6.079418      8.116356      6.566475     24.248562   \n",
       "1       21.185920     12.829356      8.488317      2.170785     28.747849   \n",
       "2       26.209789      3.273651      8.038485     13.874770     33.070410   \n",
       "3       19.968011      7.511855     17.745597      2.505243     34.382638   \n",
       "4       13.622549      5.201777      2.111775      3.481266     30.666826   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "372     36.855464     10.118797     16.890644      1.069317     26.021889   \n",
       "371     58.725989      4.130060     13.639239      7.002448     41.124935   \n",
       "296     24.108398      9.341448      2.551847      7.145349     45.700588   \n",
       "338     27.084513     15.362545      1.225671      4.086449     13.058083   \n",
       "237     28.874037     24.960603     18.450276      9.148809     59.825875   \n",
       "\n",
       "     ...  FrEM_1.5_8_0  FrEM_1.5_8_1  FrEM_1.5_8_2  FrEM_1.5_8_3  \\\n",
       "0    ...      2.626713      0.579372      0.493647      0.304215   \n",
       "1    ...      2.719659      0.752805      1.146061      0.545097   \n",
       "2    ...      2.618402      1.192939      1.087911      0.424599   \n",
       "3    ...      2.952575      1.119850      1.417656      1.717594   \n",
       "4    ...      2.827844      0.086999      0.472183      0.830620   \n",
       "..   ...           ...           ...           ...           ...   \n",
       "372  ...      1.213497      1.520239      1.408453      2.653076   \n",
       "371  ...      4.125636      0.354485      0.130846      1.322603   \n",
       "296  ...      0.866579      0.580831      0.847183      0.559834   \n",
       "338  ...      3.137124      0.416624      0.804608      0.550893   \n",
       "237  ...      2.537178      0.937049      0.918608      1.147427   \n",
       "\n",
       "     FrEM_1.5_8_4  FrEM_1.5_8_5  FrEM_1.5_8_6  FrEM_1.5_8_7  FrEM_1.5_8_8  \\\n",
       "0        0.524688      0.741711      0.647763      0.501151      0.800689   \n",
       "1        0.778240      0.335614      0.345323      0.875008      1.023703   \n",
       "2        0.430478      0.243887      1.101742      0.878708      0.708836   \n",
       "3        0.808168      0.905884      1.340841      0.749654      1.203081   \n",
       "4        0.773404      0.326004      0.659731      0.117143      0.404780   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "372      0.821519      0.340801      1.145084      0.962714      1.747128   \n",
       "371      1.304823      1.435656      0.698340      1.433633      1.348833   \n",
       "296      0.398378      0.199093      0.910787      0.342122      0.443316   \n",
       "338      0.825911      0.417157      0.861060      0.533441      0.400909   \n",
       "237      2.367507      0.956245      1.162169      1.020073      2.780852   \n",
       "\n",
       "     COVID  \n",
       "0      1.0  \n",
       "1      1.0  \n",
       "2      1.0  \n",
       "3      1.0  \n",
       "4      1.0  \n",
       "..     ...  \n",
       "372    1.0  \n",
       "371    1.0  \n",
       "296    0.0  \n",
       "338    1.0  \n",
       "237    1.0  \n",
       "\n",
       "[463 rows x 82 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463, 82)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='COVID', ylabel='Count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x=df['COVID'].map({1.0:'Yes',0.0:'No'}),shrink=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.55      0.59        40\n",
      "         1.0       0.69      0.75      0.72        53\n",
      "\n",
      "    accuracy                           0.67        93\n",
      "   macro avg       0.66      0.65      0.65        93\n",
      "weighted avg       0.66      0.67      0.66        93\n",
      "\n",
      "-----------------------------------------------\n",
      "0.60 accuracy with a standard deviation of 0.06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "X = df[df.columns[:-1]]\n",
    "Y = df[df.columns[-1]]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    random_state=41)\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3))\n",
    "\n",
    "pipe.fit(X_train, Y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test, y_pred))\n",
    "\n",
    "print('-----------------------------------------------')\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3))\n",
    "scores = cross_val_score(pipe, X, Y)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "D = len(df.columns)-1\n",
    "N = 100\n",
    "T = 10000\n",
    "F = 1  # mutation scaling factor\n",
    "\n",
    "class Agent:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.x = np.array(Agent.gen_rand_x(),dtype=np.float64)\n",
    "        self.accuracy = 0\n",
    "        self.N_sel=0\n",
    "\n",
    "    def gen_rand_x() -> list[float]:\n",
    "        x = []\n",
    "        for col in df.columns[:-1]:\n",
    "            lb = min(df[col])\n",
    "            ub = max(df[col])\n",
    "            x.append(lb+random.random()*(ub-lb))\n",
    "        return x\n",
    "\n",
    "    def fitness_func(self) -> float:\n",
    "        def to_binary(self):\n",
    "            bin = []\n",
    "            for x_i in self.x:\n",
    "                eq = 1/(1+np.exp(-x_i))\n",
    "                bin.append(eq > 0.5)\n",
    "            return bin\n",
    "\n",
    "        bin = to_binary(self)\n",
    "\n",
    "        N_sel = bin.count(True)\n",
    "        self.N_sel = N_sel\n",
    "\n",
    "        to_delete = [df.columns[i] for i in range(len(bin)) if bin[i] == False]\n",
    "\n",
    "        df1 = df.drop(to_delete, axis='columns')\n",
    "\n",
    "        X = df1[df1.columns[:-1]]\n",
    "        Y = df1[df1.columns[-1]]\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "            X,\n",
    "            Y,\n",
    "            test_size=0.2,\n",
    "            random_state=41\n",
    "        )\n",
    "\n",
    "        neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "        neigh.fit(X_train, Y_train)\n",
    "        y_pred = neigh.predict(X_test)\n",
    "\n",
    "        error = np.sum(y_pred == Y_test)/len(y_pred)\n",
    "\n",
    "        beta = random.random()\n",
    "\n",
    "        self.accuracy = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "        return beta*error+(1-beta)*N_sel/D\n",
    "\n",
    "    def Chain_Cyclone(self, t: float, i: int, x_best: np.array, agents: list['Agent']) -> None:\n",
    "        r = np.array([random.random() for i in range(len(self.x))])\n",
    "        if random.random() < 0.5:\n",
    "            r1 = random.random()\n",
    "            beta = 2*np.exp(r1*(T-t+1)/T)*np.sin(2*np.pi*r1)\n",
    "            if (t/T < random.random()):\n",
    "                # eq 13\n",
    "                if (i == 0):\n",
    "                    self.x = x_best+r*(x_best-self.x)+beta*(x_best-self.x)\n",
    "                else:\n",
    "                    self.x = x_best+r * \\\n",
    "                        (agents[i-1].x-self.x)+beta*(x_best-self.x)\n",
    "            else:\n",
    "                # eq 15\n",
    "                x_rand = Agent.gen_rand_x()\n",
    "                if (i == 0):\n",
    "                    self.x = x_rand+r*(x_rand-self.x)+beta*(x_rand-self.x)\n",
    "                else:\n",
    "                    self.x = x_rand+r*(agents[i-1].x-self.x)+beta*(x_rand-self.x)\n",
    "        else:\n",
    "            # eq 11\n",
    "            alpha = 2*np.sqrt(np.log(np.linalg.norm(r)))*r\n",
    "            if (i == 0):\n",
    "                self.x = self.x+r*(x_best-self.x)+alpha*(x_best-self.x)\n",
    "            else:\n",
    "                self.x = self.x+r*(agents[i-1].x-self.x)+alpha*(x_best-self.x)\n",
    "\n",
    "    def Somersault(self, x_best: np.array):\n",
    "        S = 2\n",
    "        r2 = random.random()\n",
    "        r3 = random.random()\n",
    "        self.x = self.x + S*(r2*x_best-r3*self.x)\n",
    "\n",
    "    def DE(self, i: int, agents: list['Agent']) -> None:\n",
    "        x_r1 = agents[random.choice(\n",
    "            [j for j in range(len(agents)) if j != i])].x\n",
    "        x_r2 = agents[random.choice(\n",
    "            [j for j in range(len(agents)) if j != i])].x\n",
    "        x_r3 = agents[random.choice(\n",
    "            [j for j in range(len(agents)) if j != i])].x\n",
    "\n",
    "        # probability already satisfied\n",
    "\n",
    "        V = Agent()\n",
    "        V.x = x_r1 + F*(x_r2 - x_r3)\n",
    "\n",
    "        if (V.fitness_func() < self.fitness_func()):\n",
    "            self.x = V.x\n",
    "\n",
    "\n",
    "def calc_Pr(i: int, ffs: list[float]) -> float:\n",
    "    sum = np.sum(ffs)\n",
    "    return ffs[i]/sum\n",
    "\n",
    "\n",
    "agents = [Agent() for i in range(N)]\n",
    "t = 0\n",
    "best_ind = 0\n",
    "while (agents[best_ind].accuracy < 0.9):\n",
    "    ffs = [agent.fitness_func() for agent in agents]\n",
    "\n",
    "    best_ind = np.argmin(ffs)\n",
    "\n",
    "    print(agents[best_ind].accuracy)\n",
    "\n",
    "    for i in range(len(agents)):\n",
    "        agents[i].Chain_Cyclone(t, i, agents[best_ind].x, agents)\n",
    "\n",
    "    for i in range(len(agents)):\n",
    "        Pr = calc_Pr(i, ffs)\n",
    "        if Pr < 0.5:\n",
    "            agents[i].Somersault(agents[best_ind].x)\n",
    "        else:\n",
    "            agents[i].DE(i, agents)\n",
    "\n",
    "    t += 1\n",
    "\n",
    "best_bin = agents[best_ind].to_binary()\n",
    "\n",
    "to_delete = [df.columns[i] for i in range(len(best_bin)) if best_bin[i] == True]\n",
    "\n",
    "print('Accuracy',agents[best_ind].accuracy,'N_sel',agents[best_ind].N_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(to_delete, axis='columns')\n",
    "\n",
    "X = df1[df1.columns[:-1]]\n",
    "Y = df1[df1.columns[-1]]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    random_state=41)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, Y_train)\n",
    "y_pred = neigh.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test, y_pred))\n",
    "print(accuracy_score(Y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f3f1f4aa92e34ad2cfd0cd346e32c9890e379cd81c62ac8989e555344d09b36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
