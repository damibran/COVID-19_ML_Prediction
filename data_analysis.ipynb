{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df = pd.read_csv('abs_data.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df[df.columns[:-1]]=scaler.fit_transform(df[df.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FrEM_1.5_0_0</th>\n",
       "      <th>FrEM_1.5_0_1</th>\n",
       "      <th>FrEM_1.5_0_2</th>\n",
       "      <th>FrEM_1.5_0_3</th>\n",
       "      <th>FrEM_1.5_0_4</th>\n",
       "      <th>FrEM_1.5_0_5</th>\n",
       "      <th>FrEM_1.5_0_6</th>\n",
       "      <th>FrEM_1.5_0_7</th>\n",
       "      <th>FrEM_1.5_0_8</th>\n",
       "      <th>FrEM_1.5_1_0</th>\n",
       "      <th>...</th>\n",
       "      <th>FrEM_1.5_8_0</th>\n",
       "      <th>FrEM_1.5_8_1</th>\n",
       "      <th>FrEM_1.5_8_2</th>\n",
       "      <th>FrEM_1.5_8_3</th>\n",
       "      <th>FrEM_1.5_8_4</th>\n",
       "      <th>FrEM_1.5_8_5</th>\n",
       "      <th>FrEM_1.5_8_6</th>\n",
       "      <th>FrEM_1.5_8_7</th>\n",
       "      <th>FrEM_1.5_8_8</th>\n",
       "      <th>COVID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.464522</td>\n",
       "      <td>-0.000279</td>\n",
       "      <td>-0.382726</td>\n",
       "      <td>-0.501013</td>\n",
       "      <td>-0.809835</td>\n",
       "      <td>-2.003255</td>\n",
       "      <td>-1.014853</td>\n",
       "      <td>-0.288300</td>\n",
       "      <td>-0.221696</td>\n",
       "      <td>-0.574850</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059312</td>\n",
       "      <td>-0.482996</td>\n",
       "      <td>-0.794010</td>\n",
       "      <td>-0.995326</td>\n",
       "      <td>-0.621466</td>\n",
       "      <td>-0.017066</td>\n",
       "      <td>-0.395275</td>\n",
       "      <td>-0.529252</td>\n",
       "      <td>-0.011077</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.454593</td>\n",
       "      <td>-0.230838</td>\n",
       "      <td>-0.980986</td>\n",
       "      <td>-1.153443</td>\n",
       "      <td>-0.154569</td>\n",
       "      <td>-0.742812</td>\n",
       "      <td>-0.182297</td>\n",
       "      <td>-0.235115</td>\n",
       "      <td>-1.062273</td>\n",
       "      <td>-0.310033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024149</td>\n",
       "      <td>-0.122418</td>\n",
       "      <td>0.402201</td>\n",
       "      <td>-0.490908</td>\n",
       "      <td>-0.109435</td>\n",
       "      <td>-0.915244</td>\n",
       "      <td>-1.030740</td>\n",
       "      <td>0.371709</td>\n",
       "      <td>0.434036</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.976096</td>\n",
       "      <td>0.514062</td>\n",
       "      <td>0.264862</td>\n",
       "      <td>-0.497222</td>\n",
       "      <td>0.218759</td>\n",
       "      <td>-0.312842</td>\n",
       "      <td>-1.360924</td>\n",
       "      <td>-0.299435</td>\n",
       "      <td>1.175851</td>\n",
       "      <td>-0.055617</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066775</td>\n",
       "      <td>0.792649</td>\n",
       "      <td>0.295582</td>\n",
       "      <td>-0.743236</td>\n",
       "      <td>-0.811718</td>\n",
       "      <td>-1.118120</td>\n",
       "      <td>0.558591</td>\n",
       "      <td>0.380626</td>\n",
       "      <td>-0.194406</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.272354</td>\n",
       "      <td>-0.374720</td>\n",
       "      <td>-0.180374</td>\n",
       "      <td>-0.106046</td>\n",
       "      <td>0.440238</td>\n",
       "      <td>-0.847047</td>\n",
       "      <td>-0.838172</td>\n",
       "      <td>1.088548</td>\n",
       "      <td>-0.998315</td>\n",
       "      <td>0.021618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233294</td>\n",
       "      <td>0.640693</td>\n",
       "      <td>0.900176</td>\n",
       "      <td>1.964355</td>\n",
       "      <td>-0.048997</td>\n",
       "      <td>0.346042</td>\n",
       "      <td>1.060970</td>\n",
       "      <td>0.069617</td>\n",
       "      <td>0.792056</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.985760</td>\n",
       "      <td>0.019822</td>\n",
       "      <td>-1.163545</td>\n",
       "      <td>-0.155811</td>\n",
       "      <td>-1.020219</td>\n",
       "      <td>-1.390127</td>\n",
       "      <td>-1.123104</td>\n",
       "      <td>-1.146873</td>\n",
       "      <td>-0.811672</td>\n",
       "      <td>-0.197086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121293</td>\n",
       "      <td>-1.506672</td>\n",
       "      <td>-0.833365</td>\n",
       "      <td>0.106992</td>\n",
       "      <td>-0.119202</td>\n",
       "      <td>-0.936500</td>\n",
       "      <td>-0.370130</td>\n",
       "      <td>-1.454678</td>\n",
       "      <td>-0.801270</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>-0.472531</td>\n",
       "      <td>-0.380436</td>\n",
       "      <td>0.017664</td>\n",
       "      <td>0.094156</td>\n",
       "      <td>0.684630</td>\n",
       "      <td>0.598273</td>\n",
       "      <td>-0.516625</td>\n",
       "      <td>0.966301</td>\n",
       "      <td>-1.272904</td>\n",
       "      <td>-0.470477</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.328304</td>\n",
       "      <td>1.473127</td>\n",
       "      <td>0.883302</td>\n",
       "      <td>3.923297</td>\n",
       "      <td>-0.022036</td>\n",
       "      <td>-0.903773</td>\n",
       "      <td>0.649658</td>\n",
       "      <td>0.583072</td>\n",
       "      <td>1.877916</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>-1.222750</td>\n",
       "      <td>-0.803756</td>\n",
       "      <td>0.610098</td>\n",
       "      <td>0.797833</td>\n",
       "      <td>1.235895</td>\n",
       "      <td>2.470073</td>\n",
       "      <td>-1.255292</td>\n",
       "      <td>0.501395</td>\n",
       "      <td>-0.138326</td>\n",
       "      <td>0.418454</td>\n",
       "      <td>...</td>\n",
       "      <td>1.286640</td>\n",
       "      <td>-0.950552</td>\n",
       "      <td>-1.459214</td>\n",
       "      <td>1.137225</td>\n",
       "      <td>0.953962</td>\n",
       "      <td>1.517758</td>\n",
       "      <td>-0.289006</td>\n",
       "      <td>1.717944</td>\n",
       "      <td>1.082960</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1.191331</td>\n",
       "      <td>0.133672</td>\n",
       "      <td>0.554550</td>\n",
       "      <td>-0.592609</td>\n",
       "      <td>-0.106389</td>\n",
       "      <td>-0.492690</td>\n",
       "      <td>-0.612505</td>\n",
       "      <td>-1.083948</td>\n",
       "      <td>-0.110999</td>\n",
       "      <td>0.687766</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.639817</td>\n",
       "      <td>-0.479963</td>\n",
       "      <td>-0.145797</td>\n",
       "      <td>-0.460047</td>\n",
       "      <td>-0.876542</td>\n",
       "      <td>-1.217192</td>\n",
       "      <td>0.157371</td>\n",
       "      <td>-0.912498</td>\n",
       "      <td>-0.724356</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-0.005465</td>\n",
       "      <td>-0.554489</td>\n",
       "      <td>-1.270369</td>\n",
       "      <td>0.086643</td>\n",
       "      <td>-0.779311</td>\n",
       "      <td>-0.237978</td>\n",
       "      <td>0.130153</td>\n",
       "      <td>-1.273573</td>\n",
       "      <td>-0.695945</td>\n",
       "      <td>-1.233496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399009</td>\n",
       "      <td>-0.821359</td>\n",
       "      <td>-0.223859</td>\n",
       "      <td>-0.478771</td>\n",
       "      <td>-0.013166</td>\n",
       "      <td>-0.734893</td>\n",
       "      <td>0.052889</td>\n",
       "      <td>-0.451438</td>\n",
       "      <td>-0.808996</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.249551</td>\n",
       "      <td>-0.137872</td>\n",
       "      <td>0.486052</td>\n",
       "      <td>-0.649897</td>\n",
       "      <td>0.336971</td>\n",
       "      <td>-0.084821</td>\n",
       "      <td>1.314004</td>\n",
       "      <td>1.189307</td>\n",
       "      <td>0.272118</td>\n",
       "      <td>1.519148</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139710</td>\n",
       "      <td>0.260638</td>\n",
       "      <td>-0.014838</td>\n",
       "      <td>0.770399</td>\n",
       "      <td>3.099980</td>\n",
       "      <td>0.457427</td>\n",
       "      <td>0.685556</td>\n",
       "      <td>0.721302</td>\n",
       "      <td>3.941123</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FrEM_1.5_0_0  FrEM_1.5_0_1  FrEM_1.5_0_2  FrEM_1.5_0_3  FrEM_1.5_0_4  \\\n",
       "0        0.464522     -0.000279     -0.382726     -0.501013     -0.809835   \n",
       "1        1.454593     -0.230838     -0.980986     -1.153443     -0.154569   \n",
       "2        0.976096      0.514062      0.264862     -0.497222      0.218759   \n",
       "3        0.272354     -0.374720     -0.180374     -0.106046      0.440238   \n",
       "4       -0.985760      0.019822     -1.163545     -0.155811     -1.020219   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "372     -0.472531     -0.380436      0.017664      0.094156      0.684630   \n",
       "371     -1.222750     -0.803756      0.610098      0.797833      1.235895   \n",
       "296      1.191331      0.133672      0.554550     -0.592609     -0.106389   \n",
       "338     -0.005465     -0.554489     -1.270369      0.086643     -0.779311   \n",
       "237      0.249551     -0.137872      0.486052     -0.649897      0.336971   \n",
       "\n",
       "     FrEM_1.5_0_5  FrEM_1.5_0_6  FrEM_1.5_0_7  FrEM_1.5_0_8  FrEM_1.5_1_0  \\\n",
       "0       -2.003255     -1.014853     -0.288300     -0.221696     -0.574850   \n",
       "1       -0.742812     -0.182297     -0.235115     -1.062273     -0.310033   \n",
       "2       -0.312842     -1.360924     -0.299435      1.175851     -0.055617   \n",
       "3       -0.847047     -0.838172      1.088548     -0.998315      0.021618   \n",
       "4       -1.390127     -1.123104     -1.146873     -0.811672     -0.197086   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "372      0.598273     -0.516625      0.966301     -1.272904     -0.470477   \n",
       "371      2.470073     -1.255292      0.501395     -0.138326      0.418454   \n",
       "296     -0.492690     -0.612505     -1.083948     -0.110999      0.687766   \n",
       "338     -0.237978      0.130153     -1.273573     -0.695945     -1.233496   \n",
       "237     -0.084821      1.314004      1.189307      0.272118      1.519148   \n",
       "\n",
       "     ...  FrEM_1.5_8_0  FrEM_1.5_8_1  FrEM_1.5_8_2  FrEM_1.5_8_3  \\\n",
       "0    ...     -0.059312     -0.482996     -0.794010     -0.995326   \n",
       "1    ...      0.024149     -0.122418      0.402201     -0.490908   \n",
       "2    ...     -0.066775      0.792649      0.295582     -0.743236   \n",
       "3    ...      0.233294      0.640693      0.900176      1.964355   \n",
       "4    ...      0.121293     -1.506672     -0.833365      0.106992   \n",
       "..   ...           ...           ...           ...           ...   \n",
       "372  ...     -1.328304      1.473127      0.883302      3.923297   \n",
       "371  ...      1.286640     -0.950552     -1.459214      1.137225   \n",
       "296  ...     -1.639817     -0.479963     -0.145797     -0.460047   \n",
       "338  ...      0.399009     -0.821359     -0.223859     -0.478771   \n",
       "237  ...     -0.139710      0.260638     -0.014838      0.770399   \n",
       "\n",
       "     FrEM_1.5_8_4  FrEM_1.5_8_5  FrEM_1.5_8_6  FrEM_1.5_8_7  FrEM_1.5_8_8  \\\n",
       "0       -0.621466     -0.017066     -0.395275     -0.529252     -0.011077   \n",
       "1       -0.109435     -0.915244     -1.030740      0.371709      0.434036   \n",
       "2       -0.811718     -1.118120      0.558591      0.380626     -0.194406   \n",
       "3       -0.048997      0.346042      1.060970      0.069617      0.792056   \n",
       "4       -0.119202     -0.936500     -0.370130     -1.454678     -0.801270   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "372     -0.022036     -0.903773      0.649658      0.583072      1.877916   \n",
       "371      0.953962      1.517758     -0.289006      1.717944      1.082960   \n",
       "296     -0.876542     -1.217192      0.157371     -0.912498     -0.724356   \n",
       "338     -0.013166     -0.734893      0.052889     -0.451438     -0.808996   \n",
       "237      3.099980      0.457427      0.685556      0.721302      3.941123   \n",
       "\n",
       "     COVID  \n",
       "0      1.0  \n",
       "1      1.0  \n",
       "2      1.0  \n",
       "3      1.0  \n",
       "4      1.0  \n",
       "..     ...  \n",
       "372    1.0  \n",
       "371    1.0  \n",
       "296    0.0  \n",
       "338    1.0  \n",
       "237    1.0  \n",
       "\n",
       "[463 rows x 82 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463, 163)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='COVID', ylabel='Count'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(x=df['COVID'].map({1.0:'Yes',0.0:'No'}),shrink=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.55      0.59        40\n",
      "         1.0       0.69      0.77      0.73        53\n",
      "\n",
      "    accuracy                           0.68        93\n",
      "   macro avg       0.67      0.66      0.66        93\n",
      "weighted avg       0.67      0.68      0.67        93\n",
      "\n",
      "0.6774193548387096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df[df.columns[:-1]]\n",
    "Y = df[df.columns[-1]]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    random_state=41)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, Y_train)\n",
    "y_pred = neigh.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test, y_pred))\n",
    "print(accuracy_score(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62 accuracy with a standard deviation of 0.05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "        \n",
    "scores = cross_val_score(neigh,X,Y)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "D = len(df.columns)-1\n",
    "N = 100\n",
    "T = 10000\n",
    "F = 1  # mutation scaling factor\n",
    "\n",
    "class Agent:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.x = np.array(Agent.gen_rand_x(),dtype=np.float64)\n",
    "        self.accuracy = 0\n",
    "        self.N_sel=0\n",
    "\n",
    "    def gen_rand_x() -> list[float]:\n",
    "        x = []\n",
    "        for col in df.columns[:-1]:\n",
    "            lb = min(df[col])\n",
    "            ub = max(df[col])\n",
    "            x.append(lb+random.random()*(ub-lb))\n",
    "        return x\n",
    "\n",
    "    def fitness_func(self) -> float:\n",
    "        def to_binary(self):\n",
    "            bin = []\n",
    "            for x_i in self.x:\n",
    "                eq = 1/(1+np.exp(-x_i))\n",
    "                bin.append(eq > 0.5)\n",
    "            return bin\n",
    "\n",
    "        bin = to_binary(self)\n",
    "\n",
    "        N_sel = bin.count(True)\n",
    "        self.N_sel = N_sel\n",
    "\n",
    "        to_delete = [df.columns[i] for i in range(len(bin)) if bin[i] == False]\n",
    "\n",
    "        df1 = df.drop(to_delete, axis='columns')\n",
    "\n",
    "        X = df1[df1.columns[:-1]]\n",
    "        Y = df1[df1.columns[-1]]\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "            X,\n",
    "            Y,\n",
    "            test_size=0.2,\n",
    "            random_state=41\n",
    "        )\n",
    "\n",
    "        neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "        neigh.fit(X_train, Y_train)\n",
    "        y_pred = neigh.predict(X_test)\n",
    "\n",
    "        error = np.sum(y_pred == Y_test)/len(y_pred)\n",
    "\n",
    "        beta = random.random()\n",
    "\n",
    "        self.accuracy = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "        return beta*error+(1-beta)*N_sel/D\n",
    "\n",
    "    def Chain_Cyclone(self, t: float, i: int, x_best: np.array, agents: list['Agent']) -> None:\n",
    "        r = np.array([random.random() for i in range(len(self.x))])\n",
    "        if random.random() < 0.5:\n",
    "            r1 = random.random()\n",
    "            beta = 2*np.exp(r1*(T-t+1)/T)*np.sin(2*np.pi*r1)\n",
    "            if (t/T < random.random()):\n",
    "                # eq 13\n",
    "                if (i == 0):\n",
    "                    self.x = x_best+r*(x_best-self.x)+beta*(x_best-self.x)\n",
    "                else:\n",
    "                    self.x = x_best+r * \\\n",
    "                        (agents[i-1].x-self.x)+beta*(x_best-self.x)\n",
    "            else:\n",
    "                # eq 15\n",
    "                x_rand = Agent.gen_rand_x()\n",
    "                if (i == 0):\n",
    "                    self.x = x_rand+r*(x_rand-self.x)+beta*(x_rand-self.x)\n",
    "                else:\n",
    "                    self.x = x_rand+r*(agents[i-1].x-self.x)+beta*(x_rand-self.x)\n",
    "        else:\n",
    "            # eq 11\n",
    "            alpha = 2*np.sqrt(np.log(np.linalg.norm(r)))*r\n",
    "            if (i == 0):\n",
    "                self.x = self.x+r*(x_best-self.x)+alpha*(x_best-self.x)\n",
    "            else:\n",
    "                self.x = self.x+r*(agents[i-1].x-self.x)+alpha*(x_best-self.x)\n",
    "\n",
    "    def Somersault(self, x_best: np.array):\n",
    "        S = 2\n",
    "        r2 = random.random()\n",
    "        r3 = random.random()\n",
    "        self.x = self.x + S*(r2*x_best-r3*self.x)\n",
    "\n",
    "    def DE(self, i: int, agents: list['Agent']) -> None:\n",
    "        x_r1 = agents[random.choice(\n",
    "            [j for j in range(len(agents)) if j != i])].x\n",
    "        x_r2 = agents[random.choice(\n",
    "            [j for j in range(len(agents)) if j != i])].x\n",
    "        x_r3 = agents[random.choice(\n",
    "            [j for j in range(len(agents)) if j != i])].x\n",
    "\n",
    "        # probability already satisfied\n",
    "\n",
    "        V = Agent()\n",
    "        V.x = x_r1 + F*(x_r2 - x_r3)\n",
    "\n",
    "        if (V.fitness_func() < self.fitness_func()):\n",
    "            self.x = V.x\n",
    "\n",
    "\n",
    "def calc_Pr(i: int, ffs: list[float]) -> float:\n",
    "    sum = np.sum(ffs)\n",
    "    return ffs[i]/sum\n",
    "\n",
    "\n",
    "agents = [Agent() for i in range(N)]\n",
    "t = 0\n",
    "best_ind = 0\n",
    "while (agents[best_ind].accuracy < 0.9):\n",
    "    ffs = [agent.fitness_func() for agent in agents]\n",
    "\n",
    "    best_ind = np.argmin(ffs)\n",
    "\n",
    "    print(agents[best_ind].accuracy)\n",
    "\n",
    "    for i in range(len(agents)):\n",
    "        agents[i].Chain_Cyclone(t, i, agents[best_ind].x, agents)\n",
    "\n",
    "    for i in range(len(agents)):\n",
    "        Pr = calc_Pr(i, ffs)\n",
    "        if Pr < 0.5:\n",
    "            agents[i].Somersault(agents[best_ind].x)\n",
    "        else:\n",
    "            agents[i].DE(i, agents)\n",
    "\n",
    "    t += 1\n",
    "\n",
    "best_bin = agents[best_ind].to_binary()\n",
    "\n",
    "to_delete = [df.columns[i] for i in range(len(best_bin)) if best_bin[i] == True]\n",
    "\n",
    "print('Accuracy',agents[best_ind].accuracy,'N_sel',agents[best_ind].N_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(to_delete, axis='columns')\n",
    "\n",
    "X = df1[df1.columns[:-1]]\n",
    "Y = df1[df1.columns[-1]]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    random_state=41)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, Y_train)\n",
    "y_pred = neigh.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test, y_pred))\n",
    "print(accuracy_score(Y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a88432943adef6e0e19f146ad8b219ddacc52c1a0d45d800f93dfafeb63dc4fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
